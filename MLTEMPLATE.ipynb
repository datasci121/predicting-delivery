{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db3aabf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from imblearn) (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.1.0)\n",
      "Requirement already satisfied: missingno in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from missingno) (3.3.4)\n",
      "Requirement already satisfied: seaborn in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from missingno) (0.11.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from missingno) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from missingno) (1.19.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (8.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->missingno) (1.15.0)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from seaborn->missingno) (1.2.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn->missingno) (2021.1)\n",
      "Requirement already satisfied: xgboost in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from xgboost) (1.19.5)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from lightgbm) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from lightgbm) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from lightgbm) (0.24.1)\n",
      "Requirement already satisfied: wheel in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from lightgbm) (0.36.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\yousuf\\anaconda3\\lib\\site-packages (0.17)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier as XGBC\n",
    "import lightgbm as lgbm\n",
    "import seaborn as sb\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as mano\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "from scipy.stats import skew, kurtosis, spearmanr as spm, pearsonr as pe, chi2_contingency\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "import statsmodels.api as sm\n",
    "import pylab as py\n",
    "from sklearn.feature_selection import RFE, RFECV, mutual_info_regression\n",
    "from sklearn import svm, tree\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import OrdinalEncoder as ordenc, OneHotEncoder as ohot, StandardScaler as StdSclr\n",
    "from sklearn.metrics import confusion_matrix as confm, accuracy_score as acs, classification_report as crep, log_loss as logloss, mean_absolute_error as MAE, mean_squared_error as MSE, r2_score as r2, precision_score as pscore, recall_score as rscore, roc_auc_score as rascore, f1_score as f1score, roc_curve as roccurve, auc \n",
    "from sklearn.model_selection import train_test_split as tts, KFold, RepeatedKFold as RKFold, StratifiedKFold as SKFold, StratifiedShuffleSplit as SSS, cross_val_score as cvl, LeaveOneOut as lvo, RepeatedStratifiedKFold as rskfold\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc, DecisionTreeRegressor as dtr\n",
    "from sklearn.linear_model import LinearRegression as LR, LogisticRegression as LogR, Ridge as rdg, Lasso as lso\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC, GradientBoostingClassifier as GBC, AdaBoostClassifier as ABC, GradientBoostingRegressor as GBR, AdaBoostRegressor as ABR, VotingRegressor as VR, RandomForestRegressor as RFR\n",
    "from sklearn.naive_bayes import GaussianNB as GNB\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier as mlpc\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures as PF\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "from statistics import mean, median, mode\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import graphviz\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2cd3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bb71420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepcopy(dataset):\n",
    "    return dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3a2c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_analysis(dataset):\n",
    "    colname = str(input(\"which column do you want to analyze? Press enter if you want to analyze the entire dataset.\"))\n",
    "    if colname != '':\n",
    "        dataset[colname].plot()\n",
    "        plt.show()\n",
    "        print(dataset[colname].describe())\n",
    "        fit = str(input(\"what type of fit do you want the qqplot to be? (None, 45, s, r, or q)\\n\"))\n",
    "        sm.qqplot(dataset[colname], line = fit)\n",
    "        plt.show()\n",
    "        plt.hist(dataset[colname])\n",
    "        plt.show()\n",
    "        dataset[colname].plot.box()\n",
    "        plt.show()\n",
    "        skewvalue = skew(dataset[colname])\n",
    "        print('The skewvalue is', skewvalue)\n",
    "        if skewvalue>-2 and skewvalue<2:\n",
    "            print(\"Normally skewed data\")\n",
    "        else:\n",
    "            print(\"Not normally skewed data\")\n",
    "        kurtosis_value = kurtosis(dataset[colname])\n",
    "        print(kurtosis_value)\n",
    "        if kurtosis_value>-7 and kurtosis_value<7:\n",
    "            print(\"Normal Kurtosis\")\n",
    "        else:\n",
    "            print(\"Not normal Kurtosis\")\n",
    "    else:\n",
    "        dataset.plot()\n",
    "        plt.show()\n",
    "        dataset.describe()\n",
    "        fit = str(input(\"what type of fit do you want the qqplot to be? (None, 45, s, r, or q)\\n\"))\n",
    "        sm.qqplot(dataset, line = fit)\n",
    "        plt.show()\n",
    "        plt.hist(dataset)\n",
    "        plt.show()\n",
    "        dataset.plot.box()\n",
    "        plt.show()\n",
    "        skewvalue = skew(dataset)\n",
    "        print(skewvalue)\n",
    "        if (skewvalue>-2).all() and (skewvalue<2).all():\n",
    "            print(\"Normally skewed data\")\n",
    "        else:\n",
    "            print(\"Not normally skewed data\")\n",
    "        kurtosis_value = kurtosis(dataset)\n",
    "        print(kurtosis_value)\n",
    "        if (kurtosis_value>-7).all() and (kurtosis_value<7).all():\n",
    "            print(\"Normal Kurtosis\")\n",
    "        else:\n",
    "            print(\"Not normal Kurtosis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b5a0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missval(dataset):\n",
    "    x = str(input(\"What analysis do you want to do? (missingval, totalmissingval, or correlation, dendogram)\"))\n",
    "    if x == 'missingval':\n",
    "        return mano.matrix(dataset)\n",
    "    elif x == 'totalmissingval':\n",
    "        return mano.bar(dataset)\n",
    "    elif x == 'correlation':\n",
    "        return mano.heatmap(dataset, figsize=(12,6))\n",
    "    elif x == 'dendo':\n",
    "        return mano.dendrogram(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34c6e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remspace(dataset):\n",
    "    colname=str(input(\"Which column do you want to remove white space in?\\n\"))\n",
    "    where = str(input(\"where do you want to remove the whitespace from?\"))\n",
    "    if colname == \"\":\n",
    "        if where == \"\":\n",
    "            dataset = dataset.str.replace(' ', '')\n",
    "        if where == \"beginning\":\n",
    "            dataset = dataset.str.lstrip()\n",
    "        if where == \"end\":\n",
    "            dataset = dataset.str.rstrip()\n",
    "        if where == \"both\":\n",
    "            dataset = dataset.str.strip()\n",
    "    else:\n",
    "        if where == \"\":\n",
    "            dataset[colname] = dataset[colname].str.replace(' ', '')\n",
    "        if where == \"beginning\":\n",
    "            dataset[colname] = dataset[colname].str.lstrip()\n",
    "        if where == \"end\":\n",
    "            dataset[colname] = dataset[colname].str.rstrip()\n",
    "        if where == \"both\":\n",
    "            dataset[colname] = dataset[colname].str.strip()\n",
    "    return dataset\n",
    "\n",
    "def repspace(dataset):\n",
    "    colname=str(input(\"Which column do you want to replace white space in?\\n\"))\n",
    "    newvalue = str(input(\"what do you want to replace the white space with?\"))\n",
    "    where = str(input(\"where do you want to put the new value?\"))\n",
    "    if colname !=\"\":\n",
    "        if where == \"beginning\":\n",
    "            dataset[colname].str.replace('^ +', newvalue)\n",
    "        elif where == \"end\":\n",
    "            dataset[colname].str.replace(' +$', newvalue)\n",
    "        elif where == \"both\":\n",
    "            dataset[colname].str.replace('^ +| +$', newvalue)\n",
    "        elif where == \"\":\n",
    "            dataset[colname].str.replace(' ', newvalue)\n",
    "    else:\n",
    "        if where == \"beginning\":\n",
    "            dataset.str.replace('^ +', newvalue)\n",
    "        elif where == \"end\":\n",
    "            dataset.str.replace(' +$', newvalue)\n",
    "        elif where == \"both\":\n",
    "            dataset.str.replace('^ +| +$', newvalue)\n",
    "        elif where == \"\":\n",
    "            dataset.str.replace(' ', newvalue)\n",
    "    return dataset\n",
    "\n",
    "def extdmy(dataset):\n",
    "    colname = str(input(\"Which column do you want to extract from?\\n\"))\n",
    "    dataset['year'] = pd.DatetimeIndex(df[colname]).year\n",
    "    dataset['month'] = pd.DatetimeIndex(df[colname]).month\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c950d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def description(name, rows):\n",
    "    print(\"The columns and rows of the dataset are\", name.shape)\n",
    "    print(\"The number of values in the dataset is\", name.size)\n",
    "    print(name.head(rows))\n",
    "    print(name.tail(rows))\n",
    "    print(name.dtypes)\n",
    "    print(name.columns)\n",
    "    return name.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdafc7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remcol(dataset):\n",
    "    colname = str(input(\"which column do you want to remove?\\n\"))\n",
    "    if colname != \"\":\n",
    "        del(dataset[colname])\n",
    "        return remcol(dataset)\n",
    "    else:\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d791ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(dataset):\n",
    "    colname = str(input(\"Which column do you want to rename?\\n\"))\n",
    "    if colname!='':\n",
    "        newcolname = str(input(\"New name of the column?\\n\"))\n",
    "        dataset.rename(columns = {colname:newcolname}, inplace = True)\n",
    "        return rename(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "217f1701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remrow(dataset):\n",
    "    colname = str(input(\"which column values do you want to remove?\\n\"))\n",
    "    if colname == 'all':\n",
    "        remrow.dataset = dataset.dropna(axis=0)\n",
    "    elif colname ==\"\":\n",
    "        row = (input(\"which row/s do you want to remove?\\n\"))\n",
    "        remrow.dataset = dataset[dataset[colname]!=row]\n",
    "        return remrow(dataset)\n",
    "    else:\n",
    "        return remrow.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa018d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadfile():\n",
    "    filetype = str(input(\"What is the file type? (csv or excel)\\n\"))\n",
    "    enc = str(input(\"What encoding do you want? (latin1 or unicode_escape)\\n\"))\n",
    "    if filetype == 'csv':\n",
    "        filepath = str(input(\"What is the filepath:\"))\n",
    "        data = pd.read_csv(filepath, index_col = None, encoding = enc)\n",
    "        return data\n",
    "    elif filetype == 'excel':\n",
    "        filepath = str(input(\"What is the filepath:\"))\n",
    "        data = pd.read_excel(filepath, index_col = None)\n",
    "        return data\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95a54d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null(dataset):    \n",
    "    return dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec0e00f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillmissingvals(dataset):\n",
    "    method = str(input(\"which method do you want to use? (KNN, SimpleImp, Interpolation, mean, median, mode)\"))\n",
    "    colname = str(input(\"which column do you want to fill?\"))\n",
    "    if method == 'mode':\n",
    "        dataset[colname].value_counts()\n",
    "        mode = input(\"what is the most occurring value?\")\n",
    "        dataset[colname].fillna(mode, inplace=True)\n",
    "    elif method == 'mean':\n",
    "        dataset[colname].fillna(data[colname].mean)\n",
    "    elif method == 'median':\n",
    "        dataset[colname].fillna(data[colname].median)\n",
    "    elif method == 'knn':\n",
    "        colname1 = str(input('Which columns do you want to use?'))\n",
    "        colname2=str(input('Which columns do you want to use?')) \n",
    "        neighbours = int(input(\"how many neighbours?\\n\"))\n",
    "        imputer = KNNImputer(n_neighbors=neighbours)\n",
    "        dataset[[colname1, colname2]] = imputer.fit_transform(dataset[[colname1, colname2]])\n",
    "        return dataset\n",
    "    elif method == 'simpleimp':\n",
    "        newcolname = str(input(\"what is the new column name?\\n\"))\n",
    "        imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        dataset[[newcolname]] = imp_mean.fit(dataset[[colname]])\n",
    "    elif method == 'Interpol':\n",
    "        submethod = str(input(\"backwards or forwards?\"))\n",
    "        newcolname = str(input(\"what is the new column name?\\n\"))\n",
    "        if submethod == 'forwards':\n",
    "            dataset[newcolname] = dataset[colname].interpolate(method ='linear', limit_direction ='forward')\n",
    "        elif submethod == 'backwards':\n",
    "            dataset[newcolname] = dataset[colname].interpolate(method ='linear', limit_direction ='backward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2ee940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def changedtype(dataset):\n",
    "    colname = str(input(\"which column do you want to change the data type for? Press enter if you want to change the data type for the entire dataset. \"))\n",
    "    if colname != '':\n",
    "        changetype = str(input(\"what data type do you want to set the column to? (string, numbers, datetime)\"))\n",
    "        if changetype == 'string':\n",
    "            dataset[colname]= dataset[colname].astype(str)\n",
    "        elif changetype == 'float':\n",
    "            dataset[colname]= dataset[colname].astype(float) #converting to float to accomodate all types of numbers\n",
    "        elif changetype == 'boolean':\n",
    "            dataset[colname]= dataset[colname].astype(bool)\n",
    "        elif changetype == 'datetime':\n",
    "            dataset[colname]=pd.to_datetime(dataset[colname])\n",
    "        elif changetype == 'numbers':\n",
    "            dataset[colname]=dataset[colname].astype(int)\n",
    "    else:\n",
    "        changetype = str(input(\"what data type do you want to set the column to? (string, numbers, datetime)\"))\n",
    "        if changetype == 'string':\n",
    "            dataset= dataset.astype(str)\n",
    "        elif changetype == 'float':\n",
    "            dataset= dataset.astype(float) #converting to float to accomodate all types of numbers\n",
    "        elif changetype == 'boolean':\n",
    "            dataset= dataset.astype(bool)\n",
    "        elif changetype == 'datetime':\n",
    "            dataset=pd.to_datetime(dataset)\n",
    "        elif changetype == 'numbers':\n",
    "            dataset=dataset.astype(int)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61bfb286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(dataset):\n",
    "    print(dataset.dtypes)\n",
    "    method = str(input(\"what do you want to do?\"))\n",
    "    if method == \"onehot\":\n",
    "        colname = str(input(\"which column do you want to encode?\"))\n",
    "        if colname != '':\n",
    "            results = ohot.fit_transform(dataset[colname])\n",
    "            newdat = pd.DataFrame(results.toarray(), columns = ohot.categories_)\n",
    "            dataset = dataset.join(newdat)\n",
    "        else: \n",
    "            results = ohot.fit_transform(dataset)\n",
    "            newdat = pd.DataFrame(results.toarray(), columns = ohot.categories_)\n",
    "            return newdat\n",
    "    elif method == 'onehot2':\n",
    "        df = pd.get_dummies(dataset)\n",
    "        return df\n",
    "    elif method == \"ordinal\":\n",
    "        colname = str(input(\"which column do you want to encode?\"))\n",
    "        if colname !='':\n",
    "            newcolname = str(input(\"set a new column name for encoded values\"))\n",
    "            dataset[newcolname] = ordenc.fit_transform(dataset[colname])\n",
    "        else:\n",
    "            return ordenc.fit_transform(dataset)\n",
    "    elif method == 'labelencoder':\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(dataset[i])\n",
    "        dataset = le.transform(dataset)\n",
    "    return dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a92433a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNalgo(X_train, X_test, y_train, y_test):  \n",
    "    neighbours = int(input(\"How many neighbours do you want?\"))\n",
    "    classifier = KNC(n_neighbors=neighbours)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(confm(y_test, y_pred))\n",
    "    print(crep(y_test, y_pred))\n",
    "    print(\"These are the predicted values: \", y_pred)\n",
    "    confmatrix = confm(y_test, y_pred)\n",
    "    print(\"The Confusion Matrix is\\n\", confmatrix)\n",
    "    Accuracy_Score = acs(y_test, y_pred)*100\n",
    "    print(\"The Accuracy Score is\\n\", Accuracy_Score)\n",
    "    precision = pscore(y_test, y_pred, pos_label = '1', labels = [0,1])*100\n",
    "    print(\"The Precision is\", precision)\n",
    "    CReport = crep(y_test, y_pred)\n",
    "    print(\"The Classification Report is\\n\", CReport)\n",
    "    LogLoss = logloss(y_test, y_pred)\n",
    "    print(\"The LogLoss is\", LogLoss)\n",
    "    fpr, tpr, _ = roccurve(y_test, y_pred)\n",
    "    AreaUnderCurve = auc(fpr, tpr)\n",
    "    print(\"The Area Under the Curve is\", AreaUnderCurve)\n",
    "    RecallScore = rscore(y_test, y_pred,pos_label='1',labels=[0,1])*100\n",
    "    print(\"The Recall Score is\", RecallScore)\n",
    "    print(\"The Specificity is\", fpr, \"and the Sensitivity is\", tpr)\n",
    "    FScore = f1score(y_test, y_pred)\n",
    "    print(\"The F-Score is\", FScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbc0cedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NVB(X_train, X_test, y_train, y_test):\n",
    "    y_pred = GNB().fit(X_train, y_train).predict(X_test)\n",
    "    print(\"These are the predicted values: \", y_pred)\n",
    "    print(\"The number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "    confmatrix = confm(y_test, y_pred)\n",
    "    print(\"The Confusion Matrix is\\n\", confmatrix)\n",
    "    Accuracy_Score = acs(y_test, y_pred)*100\n",
    "    print(\"The Accuracy Score is\\n\", Accuracy_Score)\n",
    "    precision = pscore(y_test, y_pred, pos_label = '1', labels = [0,1])*100\n",
    "    print(\"The Precision is\", precision)\n",
    "    CReport = crep(y_test, y_pred)\n",
    "    print(\"The Classification Report is\\n\", CReport)\n",
    "    LogLoss = logloss(y_test, y_pred)\n",
    "    print(\"The LogLoss is\", LogLoss)\n",
    "    fpr, tpr, _ = roccurve(y_test, y_pred)\n",
    "    AreaUnderCurve = auc(fpr, tpr)\n",
    "    print(\"The Area Under the Curve is\", AreaUnderCurve)\n",
    "    RecallScore = rscore(y_test, y_pred,pos_label='1',labels=[0,1])*100\n",
    "    print(\"The Recall Score is\", RecallScore)\n",
    "    print(\"The Specificity is\", fpr, \"and the Sensitivity is\", tpr)\n",
    "    FScore = f1score(y_test, y_pred)\n",
    "    print(\"The F-Score is\", FScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5033c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perceptron(X_train, X_test, y_train, y_test):\n",
    "    clf = mlpc(tol=1e-3, random_state=0)\n",
    "    y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "    print(\"These are the predicted values: \", y_pred)\n",
    "    print('The Perceptron score is', clf.score(X_train, y_train))\n",
    "    confmatrix = confm(y_test, y_pred)\n",
    "    print(\"The Confusion Matrix is\\n\", confmatrix)\n",
    "    Accuracy_Score = acs(y_test, y_pred)*100\n",
    "    print(\"The Accuracy Score is\\n\", Accuracy_Score)\n",
    "    precision = pscore(y_test, y_pred, pos_label = '1', labels = [0,1])*100\n",
    "    print(\"The Precision is\", precision)\n",
    "    CReport = crep(y_test, y_pred)\n",
    "    print(\"The Classification Report is\\n\", CReport)\n",
    "    LogLoss = logloss(y_test, y_pred)\n",
    "    print(\"The LogLoss is\", LogLoss)\n",
    "    fpr, tpr, _ = roccurve(y_test, y_pred)\n",
    "    AreaUnderCurve = auc(fpr, tpr)\n",
    "    print(\"The Area Under the Curve is\", AreaUnderCurve)\n",
    "    RecallScore = rscore(y_test, y_pred,pos_label='1',labels=[0,1])*100\n",
    "    print(\"The Recall Score is\", RecallScore)\n",
    "    print(\"The Specificity is\", fpr, \"and the Sensitivity is\", tpr)\n",
    "    FScore = f1score(y_test, y_pred)\n",
    "    print(\"The F-Score is\", FScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b21adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supvec(X_train, X_test, y_train, y_test):\n",
    "    knl = str(input('Which kernel do you want to apply? (linear, rbf)'))\n",
    "    c= int(input('Value of c?' ))\n",
    "    clf = svm.SVC(kernel = knl, C = c, random_state = 42)\n",
    "    y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "    print(\"These are the predicted values: \", y_pred)\n",
    "    confmatrix = confm(y_test, y_pred)\n",
    "    print(\"The Confusion Matrix is\\n\", confmatrix)\n",
    "    Accuracy_Score = acs(y_test, y_pred)*100\n",
    "    print(\"The Accuracy Score is\\n\", Accuracy_Score)\n",
    "    precision = pscore(y_test, y_pred, average = 'macro', labels = [0,1])*100\n",
    "    print(\"The Precision is\", precision)\n",
    "    CReport = crep(y_test, y_pred)\n",
    "    print(\"The Classification Report is\\n\", CReport)\n",
    "    LogLoss = logloss(y_test, y_pred)\n",
    "    print(\"The LogLoss is\", LogLoss)\n",
    "    fpr, tpr, _ = roccurve(y_test, y_pred)\n",
    "    AreaUnderCurve = auc(fpr, tpr)\n",
    "    print(\"The Area Under the Curve is\", AreaUnderCurve)\n",
    "    RecallScore = rscore(y_test, y_pred, average = 'macro',labels=[0,1])*100\n",
    "    print(\"The Recall Score is\", RecallScore)\n",
    "    print(\"The Specificity is\", fpr, \"and the Sensitivity is\", tpr)\n",
    "    FScore = f1score(y_test, y_pred)\n",
    "    print(\"The F-Score is\", FScore)\n",
    "    \n",
    "def RandFor(X_train, X_test, y_train, y_test):\n",
    "    y_pred = RFC().fit(X_train, y_train).predict(X_test)\n",
    "    print(\"These are the predicted values: \", y_pred)\n",
    "    confmatrix = confm(y_test, y_pred)\n",
    "    print(\"The Confusion Matrix is\\n\", confmatrix)\n",
    "    Accuracy_Score = acs(y_test, y_pred)*100\n",
    "    print(\"The Accuracy Score is\\n\", Accuracy_Score)\n",
    "    precision = pscore(y_test, y_pred, average = 'macro', labels = [0,1])*100\n",
    "    print(\"The Precision is\", precision)\n",
    "    CReport = crep(y_test, y_pred)\n",
    "    print(\"The Classification Report is\\n\", CReport)\n",
    "    LogLoss = logloss(y_test, y_pred)\n",
    "    print(\"The LogLoss is\", LogLoss)\n",
    "    fpr, tpr, _ = roccurve(y_test, y_pred)\n",
    "    AreaUnderCurve = auc(fpr, tpr)\n",
    "    print(\"The Area Under the Curve is\", AreaUnderCurve)\n",
    "    RecallScore = rscore(y_test, y_pred,average = 'macro',labels=[0,1])*100\n",
    "    print(\"The Recall Score is\", RecallScore)\n",
    "    print(\"The Specificity is\", fpr, \"and the Sensitivity is\", tpr)\n",
    "    FScore = f1score(y_test, y_pred)\n",
    "    print(\"The F-Score is\", FScore)\n",
    "    \n",
    "def ada(X_train, X_test, y_train, y_test):\n",
    "    y_pred = ABC().fit(X_train, y_train).predict(X_test)\n",
    "    print(\"These are the predicted values: \", y_pred)\n",
    "    confmatrix = confm(y_test, y_pred)\n",
    "    print(\"The Confusion Matrix is\\n\", confmatrix)\n",
    "    Accuracy_Score = acs(y_test, y_pred)*100\n",
    "    print(\"The Accuracy Score is\\n\", Accuracy_Score)\n",
    "    precision = pscore(y_test, y_pred, average = 'macro', labels = [0,1])*100\n",
    "    print(\"The Precision is\", precision)\n",
    "    CReport = crep(y_test, y_pred)\n",
    "    print(\"The Classification Report is\\n\", CReport)\n",
    "    LogLoss = logloss(y_test, y_pred)\n",
    "    print(\"The LogLoss is\", LogLoss)\n",
    "    fpr, tpr, _ = roccurve(y_test, y_pred)\n",
    "    AreaUnderCurve = auc(fpr, tpr)\n",
    "    print(\"The Area Under the Curve is\", AreaUnderCurve)\n",
    "    RecallScore = rscore(y_test, y_pred,average = 'macro',labels=[0,1])*100\n",
    "    print(\"The Recall Score is\", RecallScore)\n",
    "    print(\"The Specificity is\", fpr, \"and the Sensitivity is\", tpr)\n",
    "    FScore = f1score(y_test, y_pred)\n",
    "    print(\"The F-Score is\", FScore)\n",
    "\n",
    "def boostaway(X_train, X_test, y_train, y_test):\n",
    "    xg_reg = XGBC(disable_default_eval_metric=1)\n",
    "    xg_reg.fit(X_train,y_train)\n",
    "    y_pred = xg_reg.predict(X_test)\n",
    "    print(\"These are the predicted values: \", y_pred)\n",
    "    confmatrix = confm(y_test, y_pred)\n",
    "    print(\"The Confusion Matrix is\\n\", confmatrix)\n",
    "    Accuracy_Score = acs(y_test, y_pred)*100\n",
    "    print(\"The Accuracy Score is\\n\", Accuracy_Score)\n",
    "    precision = pscore(y_test, y_pred,  average = 'macro')*100\n",
    "    print(\"The Precision is\", precision)\n",
    "    CReport = crep(y_test, y_pred)\n",
    "    print(\"The Classification Report is\\n\", CReport)\n",
    "    LogLoss = logloss(y_test, y_pred)\n",
    "    print(\"The LogLoss is\", LogLoss)\n",
    "    RecallScore = rscore(y_test, y_pred, average = 'macro')*100\n",
    "    print(\"The Recall Score is\", RecallScore)\n",
    "    FScore = f1score(y_test, y_pred)\n",
    "    print(\"The F-Score is\", FScore)\n",
    "    return y_pred\n",
    "\n",
    "def light(X_train, X_test, y_train, y_test):\n",
    "    X_train = StdSclr().fit_transform(X_train, y_train)\n",
    "    X_test = StdSclr().fit_transform(X_test)\n",
    "    clf = clf = lgbm.LGBMClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"These are the predicted values: \", y_pred)\n",
    "    confmatrix = confm(y_test, y_pred)\n",
    "    print(\"The Confusion Matrix is\\n\", confmatrix)\n",
    "    Accuracy_Score = acs(y_test, y_pred)*100\n",
    "    print(\"The Accuracy Score is\\n\", Accuracy_Score)\n",
    "    precision = pscore(y_test, y_pred, pos_label = '1', labels = [0,1])*100\n",
    "    print(\"The Precision is\", precision)\n",
    "    CReport = crep(y_test, y_pred)\n",
    "    print(\"The Classification Report is\\n\", CReport)\n",
    "    LogLoss = logloss(y_test, y_pred)\n",
    "    print(\"The LogLoss is\", LogLoss)\n",
    "    fpr, tpr, _ = roccurve(y_test, y_pred)\n",
    "    AreaUnderCurve = auc(fpr, tpr)\n",
    "    print(\"The Area Under the Curve is\", AreaUnderCurve)\n",
    "    RecallScore = rscore(y_test, y_pred,pos_label='1',labels=[0,1])*100\n",
    "    print(\"The Recall Score is\", RecallScore)\n",
    "    print(\"The Specificity is\", fpr, \"and the Sensitivity is\", tpr)\n",
    "    FScore = f1score(y_test, y_pred)\n",
    "    print(\"The F-Score is\", FScore)\n",
    "\n",
    "def LogisticRegression(X_train, X_test, y_train, y_test):\n",
    "    y_pred = LogR().fit(X_train, y_train).predict(X_test)\n",
    "    print(\"These are the predicted values: \", y_pred)\n",
    "    confmatrix = confm(y_test, y_pred)\n",
    "    print(\"The Confusion Matrix is\\n\", confmatrix)\n",
    "    Accuracy_Score = acs(y_test, y_pred)*100\n",
    "    print(\"The Accuracy Score is\\n\", Accuracy_Score)\n",
    "    precision = pscore(y_test, y_pred, average = 'macro', labels = [0,1])*100\n",
    "    print(\"The Precision is\", precision)\n",
    "    CReport = crep(y_test, y_pred)\n",
    "    print(\"The Classification Report is\\n\", CReport)\n",
    "    LogLoss = logloss(y_test, y_pred)\n",
    "    print(\"The LogLoss is\", LogLoss)\n",
    "    fpr, tpr, _ = roccurve(y_test, y_pred)\n",
    "    AreaUnderCurve = auc(fpr, tpr)\n",
    "    print(\"The Area Under the Curve is\", AreaUnderCurve)\n",
    "    RecallScore = rscore(y_test, y_pred,average = 'macro',labels=[0,1])*100\n",
    "    print(\"The Recall Score is\", RecallScore)\n",
    "    print(\"The Specificity is\", fpr, \"and the Sensitivity is\", tpr)\n",
    "    FScore = f1score(y_test, y_pred)\n",
    "    print(\"The F-Score is\", FScore)\n",
    "    \n",
    "    \n",
    "def DecTree(X_train, X_test, y_train, y_test):\n",
    "    clf= dtc()\n",
    "    y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "    print(\"These are the predicted values: \", y_pred)\n",
    "    confmatrix = confm(y_test, y_pred)\n",
    "    print(\"The Confusion Matrix is\\n\", confmatrix)\n",
    "    Accuracy_Score = acs(y_test, y_pred)*100\n",
    "    print(\"The Accuracy Score is\\n\", Accuracy_Score)\n",
    "    precision = pscore(y_test, y_pred, pos_label = '1', labels = [0,1])*100\n",
    "    print(\"The Precision is\", precision)\n",
    "    CReport = crep(y_test, y_pred)\n",
    "    print(\"The Classification Report is\", CReport)\n",
    "    LogLoss = logloss(y_test, y_pred)\n",
    "    print(\"The LogLoss is\", LogLoss)\n",
    "    fpr, tpr, _ = roccurve(y_test, y_pred)\n",
    "    AreaUnderCurve = auc(fpr, tpr)\n",
    "    print(\"The Area Under the Curve is\", AreaUnderCurve)\n",
    "    RecallScore = rscore(y_test, y_pred,pos_label='1',labels=[0,1])*100\n",
    "    print(\"The Recall Score is\", RecallScore)\n",
    "    print(\"The Specificity is\", fpr, \"and the Sensitivity is\", tpr)\n",
    "    FScore = f1score(y_test, y_pred)\n",
    "    print(\"The F-Score is\", FScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96599112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(dataset):\n",
    "    y=str(input(\"What is the label column\"))\n",
    "    label=dataset[y]\n",
    "    X=dataset.drop(columns=[y])\n",
    "    X_train, X_test, y_train, y_test = tts(X, label, test_size=0.33, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a8b7762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadseries():\n",
    "    name = str(input('what is the name of file?'))\n",
    "    return pd.read_csv(name, header=0, index_col=0, parse_dates=True, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fecf5d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagset(dataset):\n",
    "    steps = int(input('How many steps do you want to lag the dataset?'))\n",
    "    return dataset.shift(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9f1b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollingmean2(dataset):\n",
    "    data = pd.DataFrame(dataset.values)\n",
    "    window2 = data.shift(2).rolling(window=2)\n",
    "    means=window2.mean()\n",
    "    rwindow2 = pd.concat([means, data],axis=1)\n",
    "    rwindow2.columns = ['mean(t-2,t-1)', 't']\n",
    "    return rwindow2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ecbc423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollingmean3(dataset):\n",
    "    data = pd.DataFrame(dataset.values)\n",
    "    window3 = data.shift(3).rolling(window=3)\n",
    "    avg = window3.mean()\n",
    "    rwindow3 = pd.concat([avg, data], axis=1)\n",
    "    rwindow3.columns = ['mean(t-3, t-2, t-1)', 't']\n",
    "    return rwindow3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c142eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularize(X_train, y_train, X_test, y_test, X, y):\n",
    "    method = str(input(\"Which regularization do you want to implement (lasso, ridge, lin regression, log regression)?\"))\n",
    "    scaler = StdSclr(copy=True, with_mean=True, with_std=True)\n",
    "    X_train = scaler.fit(X_train.fillna(0))\n",
    "    if method == 'lasso':\n",
    "        cross_val_scores_lasso = []\n",
    "        alpha = []\n",
    "        for i in range(1, 9):\n",
    "            model = lso(alpha = i * 0.25, tol=0.0925)\n",
    "            model.fit(X_train, y_train)\n",
    "            scores = cvl(model, X,y, cv = 10)\n",
    "            avg_cross_val_score = mean(scores)*100\n",
    "            cross_val_scores_lasso.append(avg_cross_val_score)\n",
    "            alpha.append(i * 0.25)\n",
    "        for i in range(0, len(alpha)):\n",
    "            print(str(alpha[i])+' : '+str(cross_val_scores_lasso[i]))\n",
    "        chosen = lso(alpha = alpha[cross_val_scores_lasso.index(max(cross_val_scores_lasso))], tol = 0.0925)\n",
    "        chosen.fit(X_train, y_train)\n",
    "        print('The regularization score of the Lasso model is', chosen.score(X_test, y_test))\n",
    "        y_pred = chosen.fit(X_train, y_train).predict(X_test)\n",
    "        print(\"These are the predicted values: \", y_pred)\n",
    "    if method == 'ridge':\n",
    "        cross_val_scores_ridge = []\n",
    "        alpha = []\n",
    "        for i in range(1, 9):\n",
    "            model = rdg(alpha = i * 0.25)\n",
    "            model.fit(X_train, y_train)\n",
    "            scores = cvl(model, X, y, cv = 10)\n",
    "            avg_cross_val_score = mean(scores)*100\n",
    "            cross_val_scores_ridge.append(avg_cross_val_score)\n",
    "            alpha.append(i * 0.25)\n",
    "        for i in range(0, len(alpha)):\n",
    "            print(str(alpha[i])+' : '+str(cross_val_scores_ridge[i]))\n",
    "        chosen = rdg(alpha = alpha[cross_val_scores_ridge.index(max(cross_val_scores_ridge))])\n",
    "        chosen.fit(X_train, y_train)\n",
    "        print('The regularization score of the Ridge model is', chosen.score(X_test, y_test))\n",
    "        y_pred = chosen.fit(X_train, y_train).predict(X_test)\n",
    "        print(\"These are the predicted values: \", y_pred)\n",
    "    if method == 'log regression':\n",
    "        model = LogR()\n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        print('The regularization score with Logarithmic Regression is', score, '.')\n",
    "        y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "    if method == 'lin regression':\n",
    "        model = LR()\n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        print('The regularization score with Linear Regression is', score, '.')\n",
    "        y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "        print(\"These are the predicted values: \", y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "67b87d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalscore(X_train, X_test, y_train, y_test):\n",
    "    testsize = float(input('What do you want the test size to be? Please input in decimal form.'))\n",
    "    knl = str(input('Which kernel do you want to apply? (linear, rbf)'))\n",
    "    clf = XGBC(disable_default_eval_metric=1)\n",
    "    score = cvl(clf, X_train, y_train, cv=5)\n",
    "    print('The normal cross validation score is', score)\n",
    "    print(\"For the normal cross validation score, there is a %0.2f accuracy with a standard deviation of %0.2f\" % (score.mean(), score.std()))\n",
    "    sscore = cvl(clf, X_train, y_train, cv=SSS(n_splits = 5, test_size=testsize, random_state=0))\n",
    "    print('The ShuffleSplit score is', sscore)\n",
    "    print(\"For the ShuffleSplit cross validation score, there is a %0.2f accuracy with a standard deviation of %0.2f\" % (sscore.mean(), sscore.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1479a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval(dataset):\n",
    "    method = str(input(\"What Fold method do you want to use?(kfold, rkfold, skfold, lvo, sss, rskfold)\"))\n",
    "    if method == 'kfold':\n",
    "        k = int(input(\"What number-fold cross validation do you want to do?\"))\n",
    "        kf= KFold(n_splits=k)\n",
    "        for train_index, test_index in kf.split(dataset):\n",
    "            trainX, testX = X.iloc[train_index], X.iloc[test_index] \n",
    "            trainY, testY = y.iloc[train_index], y.iloc[test_index]\n",
    "            return trainX, testX, trainY, testY\n",
    "    if method == 'rkfold':\n",
    "        k = int(input(\"What number-fold cross validation do you want to do?\"))\n",
    "        r = int(input(\"How many times do you want to repeat the cross validation?\"))\n",
    "        kf = RKFold(n_splits=k, n_repeats=r, random_state=random_state)\n",
    "        for train_index, test_index in kf.split(dataset):\n",
    "            trainX, testX = X.iloc[train_index], X.iloc[test_index] \n",
    "            trainY, testY = y.iloc[train_index], y.iloc[test_index]\n",
    "            return trainX, testX, trainY, testY\n",
    "    if method == 'skfold':\n",
    "        k = int(input(\"What number-fold cross validation do you want to do?\"))\n",
    "        kf = SKFold(n_splits=k, random_state=None, shuffle=False)\n",
    "        label = str(input(\"What is the label of the dataset?\"))\n",
    "        y=dataset[label]\n",
    "        X=dataset.drop([label], axis=1)\n",
    "        kf.get_n_splits(X,y)\n",
    "        print(kf)\n",
    "        for train_index, test_index in kf.split(X,y):\n",
    "            trainX, testX = X.iloc[train_index], X.iloc[test_index] \n",
    "            trainY, testY = y.iloc[train_index], y.iloc[test_index]\n",
    "            return trainX, testX, trainY, testY\n",
    "    if method == 'rskfold':\n",
    "        k = int(input(\"What number-fold cross validation do you want to do?\"))\n",
    "        r = int(input(\"How many times do you want to repeat the cross validation?\"))\n",
    "        kf = rskfold(n_splits=k, n_repeats=r, random_state=36851234)\n",
    "        label = str(input(\"What is the label of the dataset?\"))\n",
    "        y=dataset[label]\n",
    "        X=dataset.drop([label], axis=1)\n",
    "        kf.get_n_splits(X,y)\n",
    "        print(kf)\n",
    "        for train_index, test_index in kf.split(X,y):\n",
    "            trainX, testX = X.iloc[train_index], X.iloc[test_index] \n",
    "            trainY, testY = y.iloc[train_index], y.iloc[test_index]\n",
    "            return trainX, testX, trainY, testY\n",
    "    if method == 'lvo':\n",
    "        for train_index, test_index in lvo.split(dataset):\n",
    "            trainX, testX = X.iloc[train_index], X.iloc[test_index] \n",
    "            trainY, testY = y.iloc[train_index], y.iloc[test_index]\n",
    "            return trainX, testX, trainY, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c7594c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X,y):\n",
    "    estimator = SVR(kernel=\"linear\")\n",
    "    selector = RFE(estimator, n_features_to_select=5, step=1)\n",
    "    selector = selector.fit(X, y)\n",
    "    print(selector.support_)\n",
    "    print(selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd2f8f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANOVA(dataset):\n",
    "    colname1 = str(input(\"first column you want to relate\"))\n",
    "    colname2 = str(input(\"second column you want to relate\"))\n",
    "    covariance = np.cov(dataset[colname1], dataset[colname2])\n",
    "    print(\"The Covariance is \",covariance)\n",
    "    \n",
    "    corr1, _ = spm(dataset[colname1], dataset[colname2])\n",
    "    print('Spearman correlation: %.2f' % corr1)\n",
    "    corr2, _ = pe(dataset[colname1], dataset[colname2])\n",
    "    print('Pearsons correlation: %.2f' % corr2)\n",
    "    print('The t-test value is', (dataset[colname1].mean()-dataset[colname2].mean())/(math.sqrt((dataset[colname1].std()**2)/dataset[colname1].count() + (dataset[colname2].std()**2)/dataset[colname2].count())))\n",
    "    obs = np.array(dataset)\n",
    "    obs[obs<0]=0\n",
    "    chi2_contingency(obs)\n",
    "    g, p, dof, expctd = chi2_contingency(obs, lambda_=\"log-likelihood\")\n",
    "    print('The critical value of Chi-Square is', g) \n",
    "    print('The p-value is', p)\n",
    "    print('The degrees of freedom are', dof)\n",
    "    print('The expected values using the Chi-Square method are', expctd)\n",
    "    alpha = 0.05\n",
    "    if p <= alpha:\n",
    "        print('Dependent (reject H0)')\n",
    "    else:\n",
    "        print('Independent (H0 holds true)')\n",
    "    return dataset.plot(x= colname1,y=colname2,kind='scatter',alpha=0.5,cmap='rainbow')\n",
    "\n",
    "def clheatmap(dataset):\n",
    "    corrmatrix = dataset.corr()\n",
    "    colour = str(input(\"Heatmap colour?\\n\"))\n",
    "    clmap = sb.clustermap(corrmatrix, cmap = colour, linewidths = 0.2); \n",
    "    f, axis = plt.subplots(figsize =(15, 10)) \n",
    "    plt.setp(clmap.ax_heatmap.yaxis.get_majorticklabels(), rotation = 0) \n",
    "    return clmap\n",
    "\n",
    "\n",
    "def correlation_analysis(dataset):\n",
    "    numcols = dataset.select_dtypes(include=np.number)\n",
    "    corr = numcols.corr()\n",
    "    ax = sb.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sb.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    "    )\n",
    "    \n",
    "    ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "84c13623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numanalysis(dataset):\n",
    "    colname = str(input(\"which column do you want to analyze? Press enter if you want to analyze the entire dataset. \"))\n",
    "    analysis_type = str(input(\"What analysis do you want to do? (bar charts, value counts?(barchart, value counts))\"))\n",
    "    if analysis_type == 'value counts':\n",
    "        if colname != '':\n",
    "            return dataset[colname].value_counts()\n",
    "        else:\n",
    "            return dataset.value_counts()\n",
    "    elif analysis_type == 'barchart':\n",
    "        if colname != '':\n",
    "            return dataset[colname].plot.bar()\n",
    "        else:\n",
    "            return dataset[colname].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "817d4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Usampler(X,y):\n",
    "    print('Original dataset shape %s' % Counter(y))\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_res, y_res = rus.fit_resample(X, y)\n",
    "    print('Resampled dataset shape %s' % Counter(y_res))\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "06963d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Osampler(X,y):\n",
    "    print('Original dataset shape %s' % Counter(y))\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_res, y_res = ros.fit_resample(X, y)\n",
    "    print('Resampled dataset shape %s' % Counter(y_res))\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5de88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211662b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
